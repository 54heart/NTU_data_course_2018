---
title: "TF-IDF & Visualization"
author: "B05401102"
date: "2018年10月17日"
output: 
  html_document: 
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


#### **主題**：PubMed網站上Nature雜誌的文字變化分析  

#### **文字資料來源**：[PubMed(query="Nature Journal")](https://www.ncbi.nlm.nih.gov/pubmed?term=%22Nature%22%5BJournal%5D) 

#### **說明**：   
  - PubMed為美國國家醫學圖書館的生技資訊中心(NCBI)所製作的生物醫學相關文獻的書目索引摘要資料庫。文章、論文的範圍以生物醫學方面為主。
  - Nature是是全世界最權威及最有名望的學術期刊之一，發表來自很多科學領域的一手研究論文的期刊。。
  - 此次作業的目的是要分析PubMed網站上Nature論文的abstract，比較論文內容的變化趨勢。

### **1. Data Input** 
> PubMed網站提供相當方便的檢索論文方式。步驟為：

  (1) 在搜尋引擎中輸入**"Nature"[Journal]**就可以找到所有Nature雜誌的文章。
  (2) 選擇日期範圍，並選擇abstract，就會列出所有abstract的文章。我下載了**1970/1980/1990/2000/2010/2017**這六年的文字資料。
  (3) 點選**send to**→**file**，並直接下載，就可以得到txt.檔。
  (4) 輸入檔案。

> 叫出packages並輸入data。

```{r warning=FALSE}

library(NLP)
library(tm)
library(stats)
library(dplyr)
library(readtext)
library(slam)
library(Matrix)
library(tidytext)
library(stringr) 
library(wordcloud2)
library(ggplot2)
library(rvest)
library(SnowballC)                                              

#輸入文字data
filesToProcess <- list.files("pubmed_by_10",pattern = "\\.txt$")
filesToProcess
filesToProcess <- paste0("pubmed_by_10/",filesToProcess)
all.text <- do.call("rbind", lapply(filesToProcess, readtext))   

```

### **2. Data processing **  
>同上個禮拜製造文字雲的方式，將文本拆解進行文字分割，整理成詞頻矩陣。

```{r}
docs = Corpus(VectorSource(all.text))
toSpace <- content_transformer(function(x, pattern) {
  return (gsub(pattern, " ", x))
})
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))

tokenizer = function(d){
  unlist(strsplit(d[[1]], split = " "))
}
seg = lapply(docs, tokenizer)

d.corpus <- Corpus(VectorSource(seg))
tdm <- TermDocumentMatrix(d.corpus)
print( tf <- as.matrix(tdm) )
DF <- tidy(tf)
```

> 利用tf-idf將具有代表意義的字詞進行加權，顯示部分結果並輸出`show1970-2017.csv`。

```{r}
# tf-idf computation
N = tdm$ncol
tf <- apply(tdm, 2, sum)
idfCal <- function(word_doc)
{ 
  log2( N / nnzero(word_doc) ) 
}
idf <- apply(tdm, 1, idfCal)

doc.tfidf <- as.matrix(tdm)
for(x in 1:nrow(tdm))
{
  for(y in 1:ncol(tdm))
  {
    doc.tfidf[x,y] <- (doc.tfidf[x,y] / tf[y]) * idf[x]
  }
}

findZeroId = as.matrix(apply(doc.tfidf, 1, sum))
tfidfnn = doc.tfidf[-which(findZeroId == 0),]

#顯示tfidf後的結果 
head(tfidfnn)                                             

#輸出詞頻矩陣
write.csv(tfidfnn, "show1970-2017.csv")
```

### **3. Plotting **  
>建立字詞(Var1)與字詞頻率(Freq)的data frame，並刪除一些沒有比較意義的單字，依照字詞出現頻率進行排序。

```{r warning=FALSE}
freqFrame.all<-list() 
excludeWords <- c("nature","doi","pmid","university","department","pmc","pmcid","epub","institute","index", "author", "science", "can", "new", "research", "school")
for(i in 1:6){
  f = as.data.frame(table(seg[[i]]))
  freqFrameClean<- f[-which(f$Var1 %in% stopwords("en")),]
  freqFrameClean<- freqFrameClean[-which(freqFrameClean$Var1 %in% excludeWords),]
  freqFrameClean<- freqFrameClean[-which(nchar(as.character(freqFrameClean$Var1))<3),]
  freqFrame.all[[i]] <- freqFrameClean[order(freqFrameClean$Freq, decreasing = T),]
}
names(freqFrame.all) <- c("1970","1980","1990","2000","2010","2017" )
#以2017年的frequency dataframe為例
head(freqFrame.all[[6]])
```

>為了比較出不同年份的文字在生物領域上有什麼具有意義的差別，因此我利用爬蟲到wikipedia的glossary上擷取biology terms，篩選出這些terms對應的頻率。

```{r}
bioterm <- read_html("https://en.wikipedia.org/wiki/Glossary_of_biology#D") %>% html_nodes(".glossary .glossary .glossary a") %>% html_text()
splitBioterm <- unlist(strsplit(bioterm," "))

#創建只包含biology terms的新frequency dataframe
freqFrame.bio <- data.frame()
for(i in 1:6){
  addfreqFrame.bio <- freqFrame.all[[i]][which(freqFrame.all[[i]]$Var1 %in% splitBioterm),]
  addfreqFrame.bio$year <- rep(names(freqFrame.all)[i],nrow(addfreqFrame.bio))
  freqFrame.bio <- rbind(freqFrame.bio, addfreqFrame.bio)
}


#作圖


```



